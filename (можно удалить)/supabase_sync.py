#!/usr/bin/env python3
"""
GHOST Supabase Sync Module
–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å Supabase
"""

import asyncio
import sqlite3
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import os
from supabase import create_client, Client
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SupabaseSync:
    """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å Supabase"""
    
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Supabase –∫–ª–∏–µ–Ω—Ç–∞ - –ø—Ä–æ–±—É–µ–º –Ω–æ–≤—ã–µ –∫–ª—é—á–∏, –ø–æ—Ç–æ–º —Å—Ç–∞—Ä—ã–µ
        self.supabase_url = os.getenv('NEXT_PUBLIC_SUPABASE_URL')
        
        # –ü—Ä–æ–±—É–µ–º –Ω–æ–≤—ã–µ API –∫–ª—é—á–∏
        self.supabase_secret_key = os.getenv('SUPABASE_SECRET_KEY')
        if not self.supabase_secret_key:
            # Fallback –∫ —Å—Ç–∞—Ä—ã–º –∫–ª—é—á–∞–º
            self.supabase_secret_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
        
        if not self.supabase_url or not self.supabase_secret_key:
            logger.error("‚ùå Supabase credentials not found in environment variables")
            logger.error("Required: NEXT_PUBLIC_SUPABASE_URL and SUPABASE_SECRET_KEY or SUPABASE_SERVICE_ROLE_KEY")
            self.supabase = None
        else:
            self.supabase: Client = create_client(self.supabase_url, self.supabase_secret_key)
            logger.info("‚úÖ Supabase client initialized with new API keys")
    
    def get_local_news(self, db_path: str = None) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π SQLite"""
        try:
            # Use in-memory database for cloud deployment
            if db_path is None:
                # Try to find database in several locations
                possible_paths = [
                    "ghost_news.db",
                    "../ghost_news.db", 
                    "/tmp/ghost_news.db",
                    "/opt/render/project/src/ghost_news.db"
                ]
                
                db_path = None
                for path in possible_paths:
                    if os.path.exists(path):
                        db_path = path
                        break
                
                # If no database found, create in-memory database
                if db_path is None:
                    logger.warning("‚ö†Ô∏è No SQLite database found, using in-memory database")
                    db_path = ":memory:"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            import os
            current_dir = os.getcwd()
            
            if db_path != ":memory:":
                full_db_path = os.path.abspath(db_path)
                logger.info(f"üîç Current directory: {current_dir}")
                logger.info(f"üîç Database path: {full_db_path}")
                logger.info(f"üîç Database exists: {os.path.exists(full_db_path)}")
            else:
                logger.info(f"üîç Using in-memory SQLite database")
            
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
                tables = cursor.fetchall()
                logger.info(f"üîç Available tables: {[table[0] for table in tables]}")
                
                # –ü–æ–ª—É—á–∞–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ (–≤—Å–µ, –Ω–µ —Ç–æ–ª—å–∫–æ –∑–∞ 5 –º–∏–Ω—É—Ç)
                cursor.execute("""
                    SELECT id, source_name, title, content, url, published_at,
                           sentiment, urgency, is_critical, priority, market_impact
                    FROM critical_news 
                    ORDER BY created_at DESC
                    LIMIT 50
                """)
                
                critical_news = []
                for row in cursor.fetchall():
                    critical_news.append({
                        'id': row[0],
                        'source_name': row[1],
                        'title': row[2],
                        'content': row[3],
                        'url': row[4],
                        'published_at': row[5],
                        'sentiment': row[6],
                        'urgency': row[7],
                        'is_critical': bool(row[8]),
                        'priority': row[9],
                        'market_impact': row[10],
                        'local_id': row[0]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π ID
                    })
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–±—ã—á–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ (–≤—Å–µ, –Ω–µ —Ç–æ–ª—å–∫–æ –∑–∞ 5 –º–∏–Ω—É—Ç)
                cursor.execute("""
                    SELECT id, source_name, title, content, url, published_at,
                           sentiment, urgency, is_important, priority_level
                    FROM news_items 
                    ORDER BY created_at DESC
                    LIMIT 50
                """)
                
                regular_news = []
                for row in cursor.fetchall():
                    regular_news.append({
                        'id': row[0],
                        'source_name': row[1],
                        'title': row[2],
                        'content': row[3],
                        'url': row[4],
                        'published_at': row[5],
                        'sentiment': row[6],
                        'urgency': row[7],
                        'is_important': bool(row[8]),
                        'priority_level': row[9],
                        'local_id': row[0]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π ID
                    })
                
                logger.info(f"üìä Found {len(critical_news)} critical news, {len(regular_news)} regular news")
                
                return {
                    'critical_news': critical_news,
                    'regular_news': regular_news
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error reading local database: {e}")
            return {'critical_news': [], 'regular_news': []}
    
    async def sync_to_supabase(self, news_data: Dict):
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –≤ Supabase"""
        if not self.supabase:
            logger.warning("‚ö†Ô∏è Supabase not configured, skipping sync")
            return
        
        try:
            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
            if news_data['critical_news']:
                for news in news_data['critical_news']:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è –Ω–æ–≤–æ—Å—Ç—å
                    existing = self.supabase.table('critical_news').select('id').eq('local_id', news['local_id']).execute()
                    
                    if not existing.data:
                        # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –∫—Ä–∏—Ç–∏—á–µ—Å–∫—É—é –Ω–æ–≤–æ—Å—Ç—å
                        supabase_news = {
                            'local_id': news['local_id'],
                            'source_name': news['source_name'],
                            'title': news['title'],
                            'content': news['content'],
                            'url': news['url'],
                            'published_at': news['published_at'],
                            'sentiment': news['sentiment'],
                            'urgency': news['urgency'],
                            'is_critical': news['is_critical'],
                            'priority': news['priority'],
                            'market_impact': news['market_impact'],
                            'synced_at': datetime.now().isoformat()
                        }
                        
                        result = self.supabase.table('critical_news').insert(supabase_news).execute()
                        logger.info(f"‚úÖ Synced critical news: {news['title'][:50]}...")
            
            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –æ–±—ã—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
            if news_data['regular_news']:
                for news in news_data['regular_news']:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è –Ω–æ–≤–æ—Å—Ç—å
                    existing = self.supabase.table('news_items').select('id').eq('local_id', news['local_id']).execute()
                    
                    if not existing.data:
                        # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –æ–±—ã—á–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å
                        supabase_news = {
                            'local_id': news['local_id'],
                            'source_name': news['source_name'],
                            'title': news['title'],
                            'content': news['content'],
                            'url': news['url'],
                            'published_at': news['published_at'],
                            'sentiment': news['sentiment'],
                            'urgency': news['urgency'],
                            'is_important': news['is_important'],
                            'priority_level': news['priority_level'],
                            'synced_at': datetime.now().isoformat()
                        }
                        
                        result = self.supabase.table('news_items').insert(supabase_news).execute()
                        logger.info(f"‚úÖ Synced regular news: {news['title'][:50]}...")
            
            logger.info(f"üîÑ Sync completed: {len(news_data['critical_news'])} critical, {len(news_data['regular_news'])} regular")
            
        except Exception as e:
            logger.error(f"‚ùå Error syncing to Supabase: {e}")
    
    async def sync_loop(self, interval: int = 30):
        """–¶–∏–∫–ª —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
        logger.info(f"üîÑ Starting Supabase sync loop (every {interval} seconds)")
        
        while True:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                news_data = self.get_local_news()
                
                # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Å Supabase
                await self.sync_to_supabase(news_data)
                
                # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π
                await asyncio.sleep(interval)
                
            except Exception as e:
                logger.error(f"‚ùå Error in sync loop: {e}")
                await asyncio.sleep(60)  # –ü–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    sync = SupabaseSync()
    await sync.sync_loop()

if __name__ == "__main__":
    asyncio.run(main())
