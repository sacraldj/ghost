"""
GHOST Enhanced News Engine
–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –¥–≤–∏–∂–æ–∫ –¥–ª—è —Å–±–æ—Ä–∞, –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π
"""

import asyncio
import aiohttp
import sqlite3
import json
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
import hashlib
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))
from nltk.sentiment import SentimentIntensityAnalyzer
import nltk
import yaml
import os
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ghost_news_engine.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class NewsItem:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞"""
    item_type: str  # "news", "tweet", "regulatory"
    source_name: str
    author: Optional[str]
    title: str
    content: Optional[str]
    published_at: datetime
    url: Optional[str]
    external_id: Optional[str]
    influence: float = 0.0
    sentiment: float = 0.0
    urgency: float = 0.0
    source_trust: float = 0.5
    source_type: str = "unknown"
    category: Optional[str] = None
    keywords: Optional[List[str]] = None
    entities: Optional[List[str]] = None
    summary: Optional[str] = None
    is_important: bool = False
    priority_level: int = 1

class NewsEngineConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è News Engine"""
    
    def __init__(self, config_path: str = "news_engine_config.yaml"):
        self.config_path = config_path
        self.config = self._load_config()
        
    def _load_config(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        default_config = {
            "database": {
                "path": "ghost_news.db",
                "type": "sqlite"
            },
            "sources": {
                "newsapi": {
                    "enabled": True,
                    "api_key": "",
                    "base_url": "https://newsapi.org/v2",
                    "keywords": ["crypto", "bitcoin", "ethereum", "blockchain"],
                    "interval": 60
                },
                "twitter": {
                    "enabled": False,
                    "bearer_token": "",
                    "keywords": ["#crypto", "#bitcoin", "#ethereum"],
                    "interval": 30
                },
                "cryptocompare": {
                    "enabled": True,
                    "api_key": "",
                    "base_url": "https://min-api.cryptocompare.com/data",
                    "interval": 120
                }
            },
            "trust_scores": {
                "Reuters": 0.95,
                "Bloomberg": 0.90,
                "CoinTelegraph": 0.7,
                "CoinDesk": 0.8,
                "CryptoNews": 0.6,
                "*": 0.5
            },
            "influence": {
                "tweet": {
                    "weight_followers": 0.6,
                    "weight_retweets": 0.3,
                    "weight_likes": 0.1
                },
                "news": {
                    "base_influence": {
                        "Reuters": 0.9,
                        "Bloomberg": 0.9,
                        "CoinTelegraph": 0.7,
                        "UnknownBlog": 0.4
                    }
                }
            },
            "sentiment": {
                "method": "vader",
                "thresholds": {
                    "positive": 0.1,
                    "negative": -0.1
                }
            },
            "urgency": {
                "decay_hours": 24,
                "instant_keywords": ["BREAKING", "URGENT", "CRASH", "EXPLOSION"]
            },
            "processing": {
                "batch_size": 50,
                "max_retries": 3,
                "timeout": 10
            }
        }
        
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                user_config = yaml.safe_load(f)
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ —Å–ª–∏—è–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
                return self._merge_configs(default_config, user_config)
        return default_config
    
    def _merge_configs(self, default: Dict, user: Dict) -> Dict:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ —Å–ª–∏—è–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π"""
        result = default.copy()
        for key, value in user.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._merge_configs(result[key], value)
            else:
                result[key] = value
        return result

class SentimentAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è"""
    
    def __init__(self, method: str = "vader"):
        self.method = method
        if method == "vader":
            try:
                nltk.download('vader_lexicon', quiet=True)
                self.analyzer = SentimentIntensityAnalyzer()
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ VADER: {e}")
                self.analyzer = None
    
    def analyze(self, text: str) -> float:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""
        if not text or not self.analyzer:
            return 0.0
        
        try:
            scores = self.analyzer.polarity_scores(text)
            return scores["compound"]  # -1 –¥–æ 1
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è: {e}")
            return 0.0

class NewsDatabase:
    """–†–∞–±–æ—Ç–∞ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –Ω–æ–≤–æ—Å—Ç–µ–π
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS news_items (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    item_type TEXT NOT NULL,
                    source_name TEXT,
                    author TEXT,
                    title TEXT,
                    content TEXT,
                    published_at TIMESTAMP,
                    url TEXT,
                    external_id TEXT,
                    influence REAL DEFAULT 0.0,
                    sentiment REAL DEFAULT 0.0,
                    urgency REAL DEFAULT 0.0,
                    source_trust REAL DEFAULT 0.5,
                    source_type TEXT DEFAULT 'unknown',
                    category TEXT,
                    keywords TEXT,
                    entities TEXT,
                    summary TEXT,
                    is_important BOOLEAN DEFAULT FALSE,
                    priority_level INTEGER DEFAULT 1,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    content_hash TEXT,
                    UNIQUE(item_type, external_id, source_name, title, published_at)
                )
            """)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_published_at ON news_items(published_at)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_source_name ON news_items(source_name)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_sentiment ON news_items(sentiment)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_influence ON news_items(influence)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_urgency ON news_items(urgency)")
            
            # –¢–∞–±–ª–∏—Ü–∞ –¥–æ–≤–µ—Ä–∏—è –∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS source_trust (
                    source_name TEXT PRIMARY KEY,
                    trust_score REAL DEFAULT 0.5,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            conn.commit()
    
    def save_items(self, items: List[NewsItem]) -> int:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
        if not items:
            return 0
        
        saved_count = 0
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            for item in items:
                try:
                    # –°–æ–∑–¥–∞–Ω–∏–µ —Ö—ç—à–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                    content_hash = self._create_content_hash(item)
                    
                    cursor.execute("""
                        INSERT OR IGNORE INTO news_items(
                            item_type, source_name, author, title, content, 
                            published_at, url, external_id, influence, sentiment,
                            urgency, source_trust, source_type, category,
                            keywords, entities, summary, is_important, 
                            priority_level, content_hash
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        item.item_type, item.source_name, item.author, item.title,
                        item.content, item.published_at.isoformat(), item.url,
                        item.external_id, item.influence, item.sentiment,
                        item.urgency, item.source_trust, item.source_type,
                        item.category, json.dumps(item.keywords) if item.keywords else None,
                        json.dumps(item.entities) if item.entities else None,
                        item.summary, item.is_important, item.priority_level,
                        content_hash
                    ))
                    
                    if cursor.rowcount > 0:
                        saved_count += 1
                        
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–∞ {item.title[:50]}: {e}")
            
            conn.commit()
        
        return saved_count
    
    def _create_content_hash(self, item: NewsItem) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ö—ç—à–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        content = f"{item.title}{item.content or ''}{item.source_name}"
        return hashlib.sha256(content.encode()).hexdigest()
    
    def get_recent_news(self, minutes: int = 15, limit: int = 100) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–¥–∞–≤–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT * FROM news_items 
                WHERE published_at >= datetime('now', '-{} minutes')
                ORDER BY published_at DESC
                LIMIT ?
            """.format(minutes), (limit,))
            
            columns = [description[0] for description in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]

class NewsProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    def __init__(self, config: NewsEngineConfig):
        self.config = config
        self.sentiment_analyzer = SentimentAnalyzer(config.config["sentiment"]["method"])
    
    def process_item(self, item: NewsItem) -> NewsItem:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞"""
        # 1. –†–∞—Å—á–µ—Ç –¥–æ–≤–µ—Ä–∏—è –∫ –∏—Å—Ç–æ—á–Ω–∏–∫—É
        item.source_trust = self._calculate_source_trust(item.source_name)
        
        # 2. –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        text_for_sentiment = f"{item.title} {item.content or ''}"
        item.sentiment = self.sentiment_analyzer.analyze(text_for_sentiment)
        
        # 3. –†–∞—Å—á–µ—Ç –≤–ª–∏—è–Ω–∏—è
        item.influence = self._calculate_influence(item)
        
        # 4. –†–∞—Å—á–µ—Ç —Å—Ä–æ—á–Ω–æ—Å—Ç–∏
        item.urgency = self._calculate_urgency(item)
        
        # 5. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏
        item.is_important = self._is_important(item)
        
        # 6. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        item.priority_level = self._calculate_priority(item)
        
        return item
    
    def _calculate_source_trust(self, source_name: str) -> float:
        """–†–∞—Å—á–µ—Ç –¥–æ–≤–µ—Ä–∏—è –∫ –∏—Å—Ç–æ—á–Ω–∏–∫—É"""
        trust_scores = self.config.config["trust_scores"]
        return trust_scores.get(source_name, trust_scores.get("*", 0.5))
    
    def _calculate_influence(self, item: NewsItem) -> float:
        """–†–∞—Å—á–µ—Ç –≤–ª–∏—è–Ω–∏—è"""
        if item.item_type == "tweet":
            # –î–ª—è —Ç–≤–∏—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
            return min(1.0, item.source_trust * 0.8)
        else:
            # –î–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤–æ–µ –≤–ª–∏—è–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            base_influence = self.config.config["influence"]["news"]["base_influence"]
            return base_influence.get(item.source_name, 0.5)
    
    def _calculate_urgency(self, item: NewsItem) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ä–æ—á–Ω–æ—Å—Ç–∏"""
        now = datetime.now()
        age_hours = (now - item.published_at).total_seconds() / 3600
        decay_hours = self.config.config["urgency"]["decay_hours"]
        
        # –ë–∞–∑–æ–≤–∞—è —Å—Ä–æ—á–Ω–æ—Å—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        urgency = max(0.0, 1.0 - age_hours / decay_hours)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å—Ä–æ—á–Ω–æ—Å—Ç–∏
        instant_keywords = self.config.config["urgency"]["instant_keywords"]
        title_upper = item.title.upper()
        for keyword in instant_keywords:
            if keyword in title_upper:
                urgency = max(urgency, 0.9)
                break
        
        return urgency
    
    def _is_important(self, item: NewsItem) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏"""
        return (item.influence > 0.7 or 
                abs(item.sentiment) > 0.5 or 
                item.urgency > 0.8 or
                item.source_trust > 0.8)
    
    def _calculate_priority(self, item: NewsItem) -> int:
        """–†–∞—Å—á–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞"""
        priority = 1
        
        if item.is_important:
            priority += 2
        if item.urgency > 0.8:
            priority += 1
        if abs(item.sentiment) > 0.7:
            priority += 1
        if item.source_trust > 0.9:
            priority += 1
        
        return min(priority, 5)

class NewsAPIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å NewsAPI"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.base_url = config["base_url"]
        self.api_key = config["api_key"]
        self.keywords = config["keywords"]
    
    async def fetch_news(self, session: aiohttp.ClientSession) -> List[NewsItem]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ NewsAPI"""
        if not self.api_key:
            logger.warning("NewsAPI –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            return []
        
        items = []
        for keyword in self.keywords:
            try:
                url = f"{self.base_url}/everything"
                params = {
                    "q": keyword,
                    "apiKey": self.api_key,
                    "language": "en",
                    "sortBy": "publishedAt",
                    "pageSize": 20
                }
                
                async with session.get(url, params=params, timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        articles = data.get("articles", [])
                        
                        for article in articles:
                            item = NewsItem(
                                item_type="news",
                                source_name=article.get("source", {}).get("name", "Unknown"),
                                author=article.get("author"),
                                title=article.get("title", ""),
                                content=article.get("description", ""),
                                published_at=datetime.fromisoformat(article.get("publishedAt", "").replace("Z", "+00:00")),
                                url=article.get("url"),
                                external_id=article.get("url"),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º URL –∫–∞–∫ –≤–Ω–µ—à–Ω–∏–π ID
                                source_type="media"
                            )
                            items.append(item)
                    else:
                        logger.error(f"NewsAPI –æ—à–∏–±–∫–∞: {response.status}")
                        
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è {keyword}: {e}")
        
        return items

class CryptoCompareClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å CryptoCompare"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.base_url = config["base_url"]
        self.api_key = config.get("api_key", "")
    
    async def fetch_news(self, session: aiohttp.ClientSession) -> List[NewsItem]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ CryptoCompare"""
        items = []
        
        try:
            url = f"{self.base_url}/news/"
            headers = {"authorization": f"Apikey {self.api_key}"} if self.api_key else {}
            
            async with session.get(url, headers=headers, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    news_list = data.get("Data", [])
                    
                    for news in news_list:
                        item = NewsItem(
                            item_type="news",
                            source_name=news.get("source", "CryptoCompare"),
                            author=news.get("author", ""),
                            title=news.get("title", ""),
                            content=news.get("body", ""),
                            published_at=datetime.fromtimestamp(news.get("published_on", 0)),
                            url=news.get("url"),
                            external_id=str(news.get("id")),
                            source_type="crypto_media"
                        )
                        items.append(item)
                else:
                    logger.error(f"CryptoCompare –æ—à–∏–±–∫–∞: {response.status}")
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ CryptoCompare: {e}")
        
        return items

class EnhancedNewsEngine:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π News Engine"""
    
    def __init__(self, config_path: str = "news_engine_config.yaml"):
        self.config = NewsEngineConfig(config_path)
        self.db = NewsDatabase(self.config.config["database"]["path"])
        self.processor = NewsProcessor(self.config)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤
        self.clients = {}
        if self.config.config["sources"]["newsapi"]["enabled"]:
            self.clients["newsapi"] = NewsAPIClient(self.config.config["sources"]["newsapi"])
        if self.config.config["sources"]["cryptocompare"]["enabled"]:
            self.clients["cryptocompare"] = CryptoCompareClient(self.config.config["sources"]["cryptocompare"])
    
    async def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ GHOST Enhanced News Engine")
        
        async with aiohttp.ClientSession() as session:
            while True:
                try:
                    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
                    tasks = []
                    for name, client in self.clients.items():
                        tasks.append(self._fetch_with_retry(session, client))
                    
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    all_items = []
                    for result in results:
                        if isinstance(result, Exception):
                            logger.error(f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {result}")
                        else:
                            all_items.extend(result)
                    
                    if all_items:
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                        processed_items = [self.processor.process_item(item) for item in all_items]
                        saved_count = self.db.save_items(processed_items)
                        
                        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {len(all_items)} –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö")
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–∂–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
                        important_news = [item for item in processed_items if item.is_important]
                        if important_news:
                            logger.warning(f"üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(important_news)} –≤–∞–∂–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π!")
                            for news in important_news[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                                logger.warning(f"  - {news.title[:100]}... (–≤–ª–∏—è–Ω–∏–µ: {news.influence:.2f}, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {news.sentiment:.2f})")
                    
                    # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º —Ü–∏–∫–ª–æ–º
                    await asyncio.sleep(60)
                    
                except Exception as e:
                    logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ: {e}")
                    await asyncio.sleep(30)  # –ö–æ—Ä–æ—Ç–∫–∞—è –ø–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    async def _fetch_with_retry(self, session: aiohttp.ClientSession, client) -> List[NewsItem]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        max_retries = self.config.config["processing"]["max_retries"]
        
        for attempt in range(max_retries):
            try:
                return await client.fetch_news(session)
            except Exception as e:
                if attempt == max_retries - 1:
                    raise e
                logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...")
                await asyncio.sleep(5)
        
        return []

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    engine = EnhancedNewsEngine()
    await engine.run()

if __name__ == "__main__":
    asyncio.run(main())
