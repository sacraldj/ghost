#!/usr/bin/env python3
"""
GHOST | Reaction Predictor
–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–∞–∫—Ü–∏–∏ –Ω–∞ –Ω–æ–≤–æ—Å—Ç—å —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (rule-based –∏–ª–∏ —á–µ—Ä–µ–∑ GPT)
"""

import json
import sqlite3
import time
from datetime import datetime
from context_enricher import get_context_for_prediction, analyze_context_pattern
from reaction_logger import get_reaction_stats

DB_PATH = "data/predictions.db"

def init_predictions_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS news_predictions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            news_id TEXT UNIQUE,
            cluster TEXT,
            context_summary TEXT,
            predicted_reaction TEXT, -- 'pump', 'dump', 'neutral', 'short_pump_then_fade'
            predicted_change_percent REAL,
            confidence_score REAL, -- 0.0 –¥–æ 1.0
            reasoning TEXT,
            patterns_detected TEXT, -- JSON array
            similar_cases_count INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    # –ò–Ω–¥–µ–∫—Å—ã
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_news_id ON news_predictions(news_id)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_cluster ON news_predictions(cluster)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_predicted_reaction ON news_predictions(predicted_reaction)")
    
    conn.commit()
    conn.close()

def find_similar_cases(cluster, context_patterns, days=90):
    """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏"""
    conn = sqlite3.connect("data/reactions.db")
    cursor = conn.cursor()
    
    try:
        # –ò—â–µ–º —Å–ª—É—á–∞–∏ —Å —Ç–µ–º –∂–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–º
        cursor.execute("""
            SELECT reaction_type, price_change_1h, COUNT(*) as count
            FROM news_reactions 
            WHERE cluster = ? AND created_at >= datetime('now', '-{} days')
            GROUP BY reaction_type, price_change_1h
        """.format(days), (cluster,))
        
        results = cursor.fetchall()
        similar_cases = []
        
        for reaction_type, price_change, count in results:
            if price_change is not None:
                similar_cases.append({
                    "reaction_type": reaction_type,
                    "price_change": price_change,
                    "count": count
                })
        
        return similar_cases
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤: {e}")
        return []
    finally:
        conn.close()

def rule_based_prediction(cluster, context_data, patterns):
    """Rule-based –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    
    # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞
    prediction = {
        "reaction_type": "neutral",
        "predicted_change": 0.0,
        "confidence": 0.5,
        "reasoning": []
    }
    
    # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
    trend = context_data.get("trend", "sideways")
    rsi = context_data.get("rsi_14", 50)
    position_skew = context_data.get("position_skew", "neutral")
    market_phase = context_data.get("market_phase", "accumulation")
    
    # –ü—Ä–∞–≤–∏–ª–æ 1: –ü–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å + –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ = sell-the-news
    if rsi > 70 and "overbought" in patterns:
        if cluster in ["ETF_approval", "ETF_rumor", "positive_news"]:
            prediction["reaction_type"] = "short_pump_then_fade"
            prediction["predicted_change"] = -1.5
            prediction["confidence"] = 0.7
            prediction["reasoning"].append("RSI > 70 (–ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω) + –ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å = sell-the-news")
    
    # –ü—Ä–∞–≤–∏–ª–æ 2: –ü–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å + –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ = buy-the-dip
    elif rsi < 30 and "oversold" in patterns:
        if cluster in ["FOMC_hawkish", "negative_news", "regulation"]:
            prediction["reaction_type"] = "pump"
            prediction["predicted_change"] = 2.0
            prediction["confidence"] = 0.6
            prediction["reasoning"].append("RSI < 30 (–ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω) + –Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å = buy-the-dip")
    
    # –ü—Ä–∞–≤–∏–ª–æ 3: Crowded longs + –ª—é–±–∞—è –Ω–æ–≤–æ—Å—Ç—å = –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π dump
    elif position_skew == "crowded_longs":
        prediction["reaction_type"] = "dump"
        prediction["predicted_change"] = -1.0
        prediction["confidence"] = 0.6
        prediction["reasoning"].append("Crowded longs = —Ä–∏—Å–∫ –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏")
    
    # –ü—Ä–∞–≤–∏–ª–æ 4: Crowded shorts + –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ = squeeze
    elif position_skew == "crowded_shorts":
        if cluster in ["ETF_approval", "positive_news"]:
            prediction["reaction_type"] = "pump"
            prediction["predicted_change"] = 2.5
            prediction["confidence"] = 0.7
            prediction["reasoning"].append("Crowded shorts + –ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å = squeeze")
    
    # –ü—Ä–∞–≤–∏–ª–æ 5: Distribution phase + –ª—é–±–∞—è –Ω–æ–≤–æ—Å—Ç—å = dump
    elif market_phase == "distribution":
        prediction["reaction_type"] = "dump"
        prediction["predicted_change"] = -1.5
        prediction["confidence"] = 0.6
        prediction["reasoning"].append("Distribution phase = –ø—Ä–æ–¥–∞–∂–∏")
    
    # –ü—Ä–∞–≤–∏–ª–æ 6: Accumulation phase + –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ = pump
    elif market_phase == "accumulation":
        if cluster in ["ETF_approval", "positive_news"]:
            prediction["reaction_type"] = "pump"
            prediction["predicted_change"] = 1.5
            prediction["confidence"] = 0.6
            prediction["reasoning"].append("Accumulation phase + –ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å = pump")
    
    # –ü—Ä–∞–≤–∏–ª–æ 7: –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å = —É—Å–∏–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏–π
    if "high_volatility" in patterns:
        prediction["predicted_change"] *= 1.5
        prediction["reasoning"].append("–í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —É—Å–∏–ª–∏–≤–∞–µ—Ç –¥–≤–∏–∂–µ–Ω–∏—è")
    
    return prediction

def gpt_style_prediction(cluster, context_data, patterns):
    """GPT-—Å—Ç–∏–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º"""
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–ª–∞—Å—Ç–µ—Ä—É
    stats = get_reaction_stats(cluster, days=30)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    trend = context_data.get("trend", "sideways")
    rsi = context_data.get("rsi_14", 50)
    position_skew = context_data.get("position_skew", "neutral")
    market_phase = context_data.get("market_phase", "accumulation")
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
    explanation = f"–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏ —Ç–∏–ø–∞ '{cluster}' –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ:\n"
    explanation += f"‚Ä¢ –¢—Ä–µ–Ω–¥: {trend}\n"
    explanation += f"‚Ä¢ RSI: {rsi:.1f}\n"
    explanation += f"‚Ä¢ –ü–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {position_skew}\n"
    explanation += f"‚Ä¢ –§–∞–∑–∞ —Ä—ã–Ω–∫–∞: {market_phase}\n"
    explanation += f"‚Ä¢ –ü–∞—Ç—Ç–µ—Ä–Ω—ã: {', '.join(patterns)}\n"
    
    # –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    if stats:
        explanation += f"\n–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ '{cluster}':\n"
        for reaction_type, count in stats.items():
            explanation += f"‚Ä¢ {reaction_type}: {count} —Å–ª—É—á–∞–µ–≤\n"
    
    # –õ–æ–≥–∏–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    if "overbought" in patterns and cluster in ["ETF_approval", "positive_news"]:
        prediction = {
            "reaction_type": "short_pump_then_fade",
            "predicted_change": -1.8,
            "confidence": 0.75,
            "reasoning": explanation + "\n–í—ã–≤–æ–¥: –†—ã–Ω–æ–∫ –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω + –ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å = sell-the-news —ç—Ñ—Ñ–µ–∫—Ç"
        }
    elif "oversold" in patterns and cluster in ["FOMC_hawkish", "negative_news"]:
        prediction = {
            "reaction_type": "pump",
            "predicted_change": 2.2,
            "confidence": 0.65,
            "reasoning": explanation + "\n–í—ã–≤–æ–¥: –†—ã–Ω–æ–∫ –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω + –Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å = buy-the-dip"
        }
    elif position_skew == "crowded_longs":
        prediction = {
            "reaction_type": "dump",
            "predicted_change": -1.2,
            "confidence": 0.6,
            "reasoning": explanation + "\n–í—ã–≤–æ–¥: Crowded longs = —Ä–∏—Å–∫ –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏"
        }
    else:
        prediction = {
            "reaction_type": "neutral",
            "predicted_change": 0.3,
            "confidence": 0.4,
            "reasoning": explanation + "\n–í—ã–≤–æ–¥: –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è –æ–∂–∏–¥–∞–µ—Ç—Å—è"
        }
    
    return prediction

def predict_news_reaction(news_id, cluster, use_gpt_style=True):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–µ–∞–∫—Ü–∏–∏ –Ω–∞ –Ω–æ–≤–æ—Å—Ç—å"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_data = get_context_for_prediction(news_id)
        if not context_data:
            print(f"‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {news_id}")
            return None
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns = analyze_context_pattern(news_id)
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Å–ª—É—á–∞–∏
        similar_cases = find_similar_cases(cluster, patterns)
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if use_gpt_style:
            prediction = gpt_style_prediction(cluster, context_data, patterns)
        else:
            prediction = rule_based_prediction(cluster, context_data, patterns)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤
        if similar_cases:
            avg_change = sum(case["price_change"] for case in similar_cases) / len(similar_cases)
            prediction["predicted_change"] = (prediction["predicted_change"] + avg_change) / 2
            prediction["confidence"] = min(prediction["confidence"] + 0.1, 0.9)
            prediction["reasoning"] += f"\n–°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ {len(similar_cases)} –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        cursor.execute("""
            INSERT OR REPLACE INTO news_predictions 
            (news_id, cluster, context_summary, predicted_reaction, predicted_change_percent,
             confidence_score, reasoning, patterns_detected, similar_cases_count)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            news_id,
            cluster,
            f"{context_data.get('trend', 'unknown')} | RSI: {context_data.get('rsi_14', 0):.1f}",
            prediction["reaction_type"],
            prediction["predicted_change"],
            prediction["confidence"],
            prediction["reasoning"],
            json.dumps(patterns),
            len(similar_cases)
        ))
        
        conn.commit()
        print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è {news_id}: {prediction['reaction_type']} ({prediction['predicted_change']:.1f}%)")
        
        return prediction
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        conn.rollback()
        return None
    finally:
        conn.close()

def get_prediction_summary(news_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            SELECT predicted_reaction, predicted_change_percent, confidence_score, reasoning
            FROM news_predictions WHERE news_id = ?
        """, (news_id,))
        
        result = cursor.fetchone()
        if not result:
            return None
            
        reaction, change, confidence, reasoning = result
        
        summary = f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {reaction.upper()} | –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {change:.1f}% | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%}"
        
        return summary
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        return None
    finally:
        conn.close()

def get_prediction_accuracy(news_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–ø–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ —Ä–µ–∞–∫—Ü–∏—è –ø—Ä–æ–∏–∑–æ—à–ª–∞)"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        cursor.execute("""
            SELECT predicted_reaction, predicted_change_percent
            FROM news_predictions WHERE news_id = ?
        """, (news_id,))
        
        pred_result = cursor.fetchone()
        if not pred_result:
            return None
            
        predicted_reaction, predicted_change = pred_result
        
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–∞–∫—Ü–∏—é
        cursor.execute("""
            SELECT reaction_type, price_change_1h
            FROM news_reactions WHERE news_id = ?
        """, (news_id,))
        
        actual_result = cursor.fetchone()
        if not actual_result:
            return None
            
        actual_reaction, actual_change = actual_result
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
        if actual_change is None:
            return None
            
        direction_correct = (
            (predicted_change > 0 and actual_change > 0) or
            (predicted_change < 0 and actual_change < 0) or
            (abs(predicted_change) < 0.5 and abs(actual_change) < 0.5)
        )
        
        magnitude_error = abs(abs(predicted_change) - abs(actual_change))
        
        accuracy = {
            "direction_correct": direction_correct,
            "magnitude_error": magnitude_error,
            "predicted": predicted_change,
            "actual": actual_change,
            "reaction_type_match": predicted_reaction == actual_reaction
        }
        
        return accuracy
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏: {e}")
        return None
    finally:
        conn.close()

if __name__ == "__main__":
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
    init_predictions_database()
    
    # –¢–µ—Å—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    test_news_id = "test_001"
    test_cluster = "ETF_approval"
    
    prediction = predict_news_reaction(test_news_id, test_cluster, use_gpt_style=True)
    
    if prediction:
        print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {prediction}")
        
        summary = get_prediction_summary(test_news_id)
        print(f"üìä –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {summary}") 