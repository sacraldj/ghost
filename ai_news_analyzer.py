#!/usr/bin/env python3
"""
GHOST | AI News Analyzer
–ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è –ò–ò-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å GPT-4 –∏ Gemini
"""

import json
import sqlite3
import time
import requests
from datetime import datetime
import openai
import google.generativeai as genai
from context_enricher import get_market_data, enrich_news_context
from reaction_logger import log_news_event

# === API Keys ===
import yaml
with open("config/api_keys.yaml") as f:
    keys = yaml.safe_load(f)

# OpenAI GPT-4
openai.api_key = keys.get("openai", {}).get("api_key")

# Google Gemini
genai.configure(api_key=keys.get("gemini", {}).get("api_key"))
gemini_model = genai.GenerativeModel('gemini-pro')

DB_PATH = "data/ai_analysis.db"

def init_ai_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î –¥–ª—è –ò–ò-–∞–Ω–∞–ª–∏–∑–∞"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS ai_news_analysis (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            news_id TEXT UNIQUE,
            cluster TEXT,
            gpt_analysis TEXT,
            gemini_analysis TEXT,
            final_verdict TEXT,
            confidence_score REAL,
            similar_cases_found INTEGER,
            market_context TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS news_clusters (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            news_id TEXT UNIQUE,
            cluster TEXT,
            significance_score REAL, -- 0.0 –¥–æ 1.0
            is_important BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    conn.commit()
    conn.close()

def filter_and_cluster_news(news_data):
    """–°–ª–æ–π 1: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä –Ω–æ–≤–æ—Å—Ç–∏
    title = news_data.get("title", "").lower()
    content = news_data.get("content", "").lower()
    
    clusters = {
        "ETF_approval": ["etf", "sec", "approval", "bitcoin etf"],
        "FOMC_meeting": ["fomc", "federal reserve", "interest rate", "fed"],
        "CPI_report": ["cpi", "inflation", "consumer price"],
        "regulation": ["regulation", "sec", "cfdc", "legal"],
        "institutional": ["institutional", "blackrock", "fidelity", "adoption"],
        "technical": ["technical", "support", "resistance", "breakout"],
        "macro": ["macro", "economy", "recession", "growth"]
    }
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä
    detected_cluster = "general"
    max_matches = 0
    
    for cluster, keywords in clusters.items():
        matches = sum(1 for keyword in keywords if keyword in title or keyword in content)
        if matches > max_matches:
            max_matches = matches
            detected_cluster = cluster
    
    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
    significance_score = calculate_significance(news_data, detected_cluster)
    
    return {
        "cluster": detected_cluster,
        "significance_score": significance_score,
        "is_important": significance_score > 0.7
    }

def calculate_significance(news_data, cluster):
    """–û—Ü–µ–Ω–∫–∞ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏"""
    score = 0.0
    
    # –ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–æ–≤–æ—Å—Ç–∏
    source = news_data.get("source", "").lower()
    if source in ["reuters", "bloomberg", "cnbc", "wsj"]:
        score += 0.3
    elif source in ["coindesk", "cointelegraph"]:
        score += 0.2
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    title = news_data.get("title", "").lower()
    important_keywords = ["approval", "rejection", "announcement", "decision", "official"]
    score += sum(0.1 for keyword in important_keywords if keyword in title)
    
    # –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤–∞–∂–Ω–µ–µ)
    content_length = len(news_data.get("content", ""))
    if content_length > 500:
        score += 0.2
    
    # –ö–ª–∞—Å—Ç–µ—Ä–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å
    cluster_importance = {
        "ETF_approval": 0.9,
        "FOMC_meeting": 0.8,
        "CPI_report": 0.7,
        "regulation": 0.6,
        "institutional": 0.5,
        "technical": 0.3,
        "macro": 0.4
    }
    
    score += cluster_importance.get(cluster, 0.3)
    
    return min(score, 1.0)

def gpt_context_analysis(news_data, market_context):
    """–°–ª–æ–π 2: GPT-4 –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    
    try:
        prompt = f"""
        –¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–µ—Ä —Å 10+ –ª–µ—Ç –æ–ø—ã—Ç–∞. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç—å:

        –ù–û–í–û–°–¢–¨:
        –ó–∞–≥–æ–ª–æ–≤–æ–∫: {news_data.get('title', '')}
        –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {news_data.get('content', '')}
        –ò—Å—Ç–æ—á–Ω–∏–∫: {news_data.get('source', '')}
        –ö–ª–∞—Å—Ç–µ—Ä: {news_data.get('cluster', '')}

        –ö–û–ù–¢–ï–ö–°–¢ –†–´–ù–ö–ê:
        –¢—Ä–µ–Ω–¥: {market_context.get('trend', '')}
        RSI: {market_context.get('rsi_14', 0)}
        –ü–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {market_context.get('position_skew', '')}
        –§–∞–∑–∞ —Ä—ã–Ω–∫–∞: {market_context.get('market_phase', '')}

        –ê–ù–ê–õ–ò–ó:
        1. –ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç —ç—Ç–∞ –Ω–æ–≤–æ—Å—Ç—å –¥–ª—è —Ä—ã–Ω–∫–∞?
        2. –ö–∞–∫ —Ä—ã–Ω–æ–∫ –æ—Ç—Ä–µ–∞–≥–∏—Ä—É–µ—Ç –≤ –¥–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ?
        3. –ö–∞–∫–∏–µ —Ä–∏—Å–∫–∏ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏?
        4. –û–∂–∏–¥–∞–µ–º–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ —Ü–µ–Ω—ã (–≤ %)
        5. –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ (0-100%)

        –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {{
            "analysis": "–∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑",
            "expected_reaction": "pump/dump/neutral",
            "price_movement": 1.5,
            "confidence": 75,
            "risks": ["—Å–ø–∏—Å–æ–∫ —Ä–∏—Å–∫–æ–≤"],
            "opportunities": ["—Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"]
        }}
        """
        
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        gpt_response = response.choices[0].message.content
        
        # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
        try:
            analysis = json.loads(gpt_response)
            return analysis
        except:
            return {"error": "Failed to parse GPT response"}
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ GPT –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return {"error": str(e)}

def gemini_pattern_analysis(news_id, cluster, market_context):
    """–°–ª–æ–π 3: Gemini –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        conn = sqlite3.connect("data/reactions.db")
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT title, reaction_type, price_change_1h, created_at
            FROM news_reactions 
            WHERE cluster = ? AND created_at >= datetime('now', '-90 days')
            ORDER BY created_at DESC
            LIMIT 10
        """, (cluster,))
        
        historical_cases = cursor.fetchall()
        conn.close()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è Gemini
        historical_text = ""
        for title, reaction, change, date in historical_cases:
            historical_text += f"- {date}: {title} ‚Üí {reaction} ({change:.1f}%)\n"
        
        prompt = f"""
        –¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ä—ã–Ω–æ—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:

        –¢–ï–ö–£–©–ê–Ø –ù–û–í–û–°–¢–¨: {news_id}
        –ö–õ–ê–°–¢–ï–†: {cluster}
        –†–´–ù–û–ß–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢: {market_context}

        –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–ï –°–õ–£–ß–ê–ò:
        {historical_text}

        –ó–ê–î–ê–ß–ê:
        1. –ù–∞–π–¥–∏ –ø–æ—Ö–æ–∂–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –∏—Å—Ç–æ—Ä–∏–∏
        2. –û–ø—Ä–µ–¥–µ–ª–∏ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ä–µ–∞–∫—Ü–∏–∏
        3. –°–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–π —Ä–µ–∞–∫—Ü–∏—é –Ω–∞ —Ç–µ–∫—É—â—É—é –Ω–æ–≤–æ—Å—Ç—å
        4. –û—Ü–µ–Ω–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ

        –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {{
            "similar_patterns": ["–æ–ø–∏—Å–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"],
            "expected_reaction": "pump/dump/neutral",
            "confidence": 80,
            "reasoning": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ",
            "similar_cases_count": 5
        }}
        """
        
        response = gemini_model.generate_content(prompt)
        gemini_response = response.text
        
        # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
        try:
            analysis = json.loads(gemini_response)
            return analysis
        except:
            return {"error": "Failed to parse Gemini response"}
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ Gemini –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return {"error": str(e)}

def synthesize_ai_insights(gpt_analysis, gemini_analysis, market_context):
    """–°–ª–æ–π 4: –°–∏–Ω—Ç–µ–∑ –≤—ã–≤–æ–¥–æ–≤ –≤—Å–µ—Ö –ò–ò"""
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∏ –≤ –∞–Ω–∞–ª–∏–∑–∞—Ö
    if "error" in gpt_analysis or "error" in gemini_analysis:
        return {
            "final_verdict": "neutral",
            "confidence": 0.3,
            "reasoning": "–û—à–∏–±–∫–∞ –≤ –ò–ò-–∞–Ω–∞–ª–∏–∑–µ"
        }
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤—ã–≤–æ–¥—ã GPT –∏ Gemini
    gpt_reaction = gpt_analysis.get("expected_reaction", "neutral")
    gemini_reaction = gemini_analysis.get("expected_reaction", "neutral")
    
    gpt_confidence = gpt_analysis.get("confidence", 50) / 100
    gemini_confidence = gemini_analysis.get("confidence", 50) / 100
    
    # –ï—Å–ª–∏ –ò–ò —Å–æ–≥–ª–∞—Å–Ω—ã
    if gpt_reaction == gemini_reaction:
        final_verdict = gpt_reaction
        confidence = (gpt_confidence + gemini_confidence) / 2
        reasoning = f"GPT –∏ Gemini —Å–æ–≥–ª–∞—Å–Ω—ã: {gpt_reaction}"
    else:
        # –í—ã–±–∏—Ä–∞–µ–º –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑
        if gpt_confidence > gemini_confidence:
            final_verdict = gpt_reaction
            confidence = gpt_confidence * 0.8  # –°–Ω–∏–∂–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–∏ —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è—Ö
            reasoning = f"GPT –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω: {gpt_reaction}"
        else:
            final_verdict = gemini_reaction
            confidence = gemini_confidence * 0.8
            reasoning = f"Gemini –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω: {gemini_reaction}"
    
    return {
        "final_verdict": final_verdict,
        "confidence": confidence,
        "reasoning": reasoning,
        "gpt_analysis": gpt_analysis,
        "gemini_analysis": gemini_analysis
    }

def analyze_news_with_ai(news_data):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–æ–≥–æ –ò–ò-–∞–Ω–∞–ª–∏–∑–∞"""
    
    # –°–ª–æ–π 1: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
    clustering = filter_and_cluster_news(news_data)
    news_data["cluster"] = clustering["cluster"]
    
    # –ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å –Ω–µ –≤–∞–∂–Ω–∞—è - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    if not clustering["is_important"]:
        print(f"‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç—å {news_data.get('news_id')} –Ω–µ –≤–∞–∂–Ω–∞—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
        return None
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ
    log_news_event(news_data)
    
    # –û–±–æ–≥–∞—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    market_context = enrich_news_context(news_data["news_id"])
    if not market_context:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è {news_data['news_id']}")
        return None
    
    # –°–ª–æ–π 2: GPT –∞–Ω–∞–ª–∏–∑
    print(f"üß† GPT –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç {news_data['news_id']}...")
    gpt_analysis = gpt_context_analysis(news_data, market_context)
    
    # –°–ª–æ–π 3: Gemini –∞–Ω–∞–ª–∏–∑
    print(f"ü§ñ Gemini –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç {news_data['news_id']}...")
    gemini_analysis = gemini_pattern_analysis(
        news_data["news_id"], 
        clustering["cluster"], 
        market_context
    )
    
    # –°–ª–æ–π 4: –°–∏–Ω—Ç–µ–∑
    final_verdict = synthesize_ai_insights(gpt_analysis, gemini_analysis, market_context)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            INSERT OR REPLACE INTO ai_news_analysis 
            (news_id, cluster, gpt_analysis, gemini_analysis, final_verdict,
             confidence_score, market_context)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            news_data["news_id"],
            clustering["cluster"],
            json.dumps(gpt_analysis),
            json.dumps(gemini_analysis),
            final_verdict["final_verdict"],
            final_verdict["confidence"],
            json.dumps(market_context)
        ))
        
        conn.commit()
        print(f"‚úÖ –ò–ò-–∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {final_verdict['final_verdict']} ({final_verdict['confidence']:.1%})")
        
        return {
            "news_id": news_data["news_id"],
            "cluster": clustering["cluster"],
            "final_verdict": final_verdict,
            "gpt_analysis": gpt_analysis,
            "gemini_analysis": gemini_analysis
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
        conn.rollback()
        return None
    finally:
        conn.close()

def get_ai_analysis_summary(news_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –ò–ò-–∞–Ω–∞–ª–∏–∑–∞"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            SELECT final_verdict, confidence_score, gpt_analysis, gemini_analysis
            FROM ai_news_analysis WHERE news_id = ?
        """, (news_id,))
        
        result = cursor.fetchone()
        if not result:
            return None
            
        verdict, confidence, gpt_json, gemini_json = result
        
        gpt_analysis = json.loads(gpt_json) if gpt_json else {}
        gemini_analysis = json.loads(gemini_json) if gemini_json else {}
        
        summary = f"–ò–ò-–í–ï–†–î–ò–ö–¢: {verdict.upper()} | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%}\n"
        summary += f"GPT: {gpt_analysis.get('expected_reaction', 'N/A')} ({gpt_analysis.get('confidence', 0)}%)\n"
        summary += f"Gemini: {gemini_analysis.get('expected_reaction', 'N/A')} ({gemini_analysis.get('confidence', 0)}%)"
        
        return summary
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return None
    finally:
        conn.close()

if __name__ == "__main__":
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
    init_ai_database()
    
    # –¢–µ—Å—Ç –ò–ò-–∞–Ω–∞–ª–∏–∑–∞
    test_news = {
        "news_id": "ai_test_001",
        "title": "SEC Approves Bitcoin ETF - Major Milestone for Crypto",
        "content": "The Securities and Exchange Commission has officially approved the first Bitcoin ETF, marking a historic moment for cryptocurrency adoption...",
        "source": "Reuters",
        "published_at": datetime.now().isoformat(),
        "symbol": "BTCUSDT"
    }
    
    result = analyze_news_with_ai(test_news)
    
    if result:
        print(f"‚úÖ –ò–ò-–∞–Ω–∞–ª–∏–∑: {result}")
        
        summary = get_ai_analysis_summary("ai_test_001")
        print(f"üìä –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {summary}") 