#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å—Ö–µ–º—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø–æ–ª—è –∏–∑ —Å—Ö–µ–º—ã –î–∞—Ä—ç–Ω–∞ —Å –Ω–∞—à–∏–º–∏ —Å—Ö–µ–º–∞–º–∏ Prisma –∏ Supabase
"""

import re
from typing import Set, Dict, List

# –ü–æ–ª—è –∏–∑ —Å—Ö–µ–º—ã –î–∞—Ä—ç–Ω–∞ (SQLite)
DARRIN_FIELDS = {
    'id', 'trade_id', 'symbol', 'side', 'leverage', 'source', 'source_type', 'source_name', 'source_id',
    'entry_zone', 'entry_type', 'entry_exec_price', 'entry', 'fill_type', 'tp1', 'tp2', 'tp3', 'sl',
    'tp1_price', 'tp2_price', 'sl_price', 'tp1_auto_calc', 'sl_auto_calc', 'sl_type', 'real_entry_price',
    'position_qty', 'margin_usd', 'verdict_reason', 'opened_at', 'updated_at', 'real_leverage',
    'margin_used', 'entry_min', 'entry_max', 'avg_entry_price', 'entry_method', 'risk_pct',
    'source_leverage', 'raw_symbol', 'targets', 'tp_weights', 'original_text', 'exit_time',
    'exit_reason', 'roi_percent', 'verdict', 'gpt_comment', 'exit_trigger_type', 'exit_trigger_value',
    'ghost_exit_score', 'order_id', 'execution_type', 'fill_status', 'avg_fill_price', 'fee_rate',
    'fee_paid', 'model_id', 'strategy_version', 'signal_sequence', 'consensus_score',
    'consensus_sources', 'status', 'closed_at', 'realized_pnl', 'exit', 'finalized', 'roi_planned',
    'pnl_gross', 'pnl_net', 'roi_gross', 'entry_price_bybit', 'exit_price_bybit', 'exit_price_fallback',
    'roi_percent_bybit', 'roi_estimated', 'entry_slippage', 'exit_slippage', 'entry_latency_ms',
    'exit_latency_ms', 'data_source_mode', 'weekday', 'roi_bybit_style', 'bybit_fee_open',
    'bybit_fee_close', 'bybit_fee_total', 'bybit_pnl_net', 'weekday_name', 'opened_at_full',
    'commission_over_roi', 'loss_type', 'anomaly_flag', 'bybit_pnl_net_api', 'order_id_exit',
    'signal_id', 'bybit_pnl_net_fallback', 'order_id_exit_fallback', 'roi_source', 'tp_hit',
    'exit_detail', 'roi_ui', 'pnl_net_initial', 'roi_percent_initial', 'tp1_hit', 'tp2_hit',
    'sl_hit', 'early_exit', 'early_exit_reason', 'exit_explanation', 'exit_ai_score',
    'tp_count_hit', 'roi_sl_expected', 'expected_profit_tp1', 'expected_loss_sl', 'duration_sec',
    'leverage_used_expected', 'strategy_id', 'tp1_order_id', 'tp2_order_id', 'sl_order_id',
    'sl_be_moved', 'sl_be_method', 'tp2_restore_attempted', 'tp2_order_id_current',
    'tp2_order_id_history', 'sl_order_id_current', 'sl_order_id_history', 'tp2_restore_attempts',
    'pnl_tp1', 'pnl_tp2', 'roi_tp1', 'roi_tp2', 'roi_final_real', 'pnl_final_real',
    'profit_tp1_real', 'profit_tp2_real', 'fee_tp1', 'fee_tp2', 'pnl_tp1_net', 'pnl_tp2_net',
    'roi_tp1_real', 'roi_tp2_real', 'roi_sl_real', 'tp2_exit_type', 'tp1_hit_time',
    'tp2_hit_time', 'sl_hit_time', 'tp1_duration_sec', 'tp2_duration_sec', 'sl_duration_sec',
    'expected_profit_tp2', 'expected_profit_total', 'manual_exit', 'manual_exit_type',
    'sl_to_be', 'sl_be_price', 'pnl_source', 'raw_fills_count', 'fills_legA', 'fills_legB',
    'fills_legA_vwap', 'fills_legB_vwap', 'fills_legA_qty', 'fills_legB_qty', 'fills_legA_fee',
    'fills_legB_fee', 'fills_legA_fee_in', 'fills_legB_fee_in'
}

def extract_prisma_fields(prisma_file: str) -> Set[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª—è –∏–∑ Prisma —Å—Ö–µ–º—ã"""
    try:
        with open(prisma_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ò—â–µ–º –ø–æ–ª—è –≤ –º–æ–¥–µ–ª–∏ Trade
        trade_model_match = re.search(r'model Trade\s*\{([^}]+)\}', content, re.DOTALL)
        if not trade_model_match:
            return set()
        
        trade_content = trade_model_match.group(1)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º–µ–Ω–∞ –ø–æ–ª–µ–π
        field_pattern = r'(\w+)\s+[\w<>\[\]?]+'
        fields = set()
        
        for line in trade_content.split('\n'):
            line = line.strip()
            if line and not line.startswith('//') and not line.startswith('@@'):
                match = re.search(field_pattern, line)
                if match:
                    field_name = match.group(1)
                    if field_name not in ['profile', 'Profile']:  # –ò—Å–∫–ª—é—á–∞–µ–º —Å–≤—è–∑–∏
                        fields.add(field_name)
        
        return fields
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª {prisma_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return set()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {prisma_file}: {e}")
        return set()

def extract_supabase_fields(sql_file: str) -> Set[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª—è –∏–∑ SQL –º–∏–≥—Ä–∞—Ü–∏–∏ Supabase"""
    try:
        with open(sql_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ò—â–µ–º CREATE TABLE trades
        create_table_match = re.search(r'CREATE TABLE trades\s*\(([\s\S]*?)\);', content, re.IGNORECASE)
        if not create_table_match:
            print(f"‚ùå CREATE TABLE trades –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {sql_file}")
            return set()
        
        table_content = create_table_match.group(1)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º–µ–Ω–∞ –ø–æ–ª–µ–π
        fields = set()
        lines = table_content.split('\n')
        
        for line in lines:
            line = line.strip()
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            if not line or line.startswith('--') or line.startswith('@@'):
                continue
            
            # –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏
            line = re.sub(r'--.*$', '', line)
            line = line.strip()
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
            if not line or line.startswith('--'):
                continue
            
            # –ò—â–µ–º –∏–º—è –ø–æ–ª—è (–ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –≤ —Å—Ç—Ä–æ–∫–µ)
            field_match = re.search(r'^(\w+)', line)
            if field_match:
                field_name = field_match.group(1)
                # –ò—Å–∫–ª—é—á–∞–µ–º SQL –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
                if field_name not in ['PRIMARY', 'KEY', 'REFERENCES', 'ON', 'DELETE', 'CASCADE', 'CHECK', 'IN', 'LONG', 'SHORT', 'DEFAULT', 'NOT', 'NULL', 'UNIQUE', 'CONSTRAINT']:
                    fields.add(field_name)
        
        return fields
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª {sql_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return set()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {sql_file}: {e}")
        return set()

def check_compatibility():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å—Ö–µ–º"""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å—Ö–µ–º—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Prisma —Å—Ö–µ–º—É
    print("\nüìã Prisma Schema (prisma/schema.prisma):")
    prisma_fields = extract_prisma_fields('prisma/schema.prisma')
    if prisma_fields:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ–π: {len(prisma_fields)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è
        missing_in_prisma = DARRIN_FIELDS - prisma_fields
        if missing_in_prisma:
            print(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è ({len(missing_in_prisma)}):")
            for field in sorted(missing_in_prisma):
                print(f"   - {field}")
        else:
            print("‚úÖ –í—Å–µ –ø–æ–ª—è –∏–∑ —Å—Ö–µ–º—ã –î–∞—Ä—ç–Ω–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–æ–ª—è –∏–∑ Prisma —Å—Ö–µ–º—ã")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Supabase –º–∏–≥—Ä–∞—Ü–∏—é
    print("\nüóÑÔ∏è Supabase Migration (supabase_complete_migration.sql):")
    supabase_fields = extract_supabase_fields('supabase_complete_migration.sql')
    if supabase_fields:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ–π: {len(supabase_fields)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è
        missing_in_supabase = DARRIN_FIELDS - supabase_fields
        if missing_in_supabase:
            print(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è ({len(missing_in_supabase)}):")
            for field in sorted(missing_in_supabase):
                print(f"   - {field}")
        else:
            print("‚úÖ –í—Å–µ –ø–æ–ª—è –∏–∑ —Å—Ö–µ–º—ã –î–∞—Ä—ç–Ω–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–æ–ª—è –∏–∑ Supabase –º–∏–≥—Ä–∞—Ü–∏–∏")
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   - –í—Å–µ–≥–æ –ø–æ–ª–µ–π –≤ —Å—Ö–µ–º–µ –î–∞—Ä—ç–Ω–∞: {len(DARRIN_FIELDS)}")
    print(f"   - –ü–æ–ª—è –≤ Prisma: {len(prisma_fields)}")
    print(f"   - –ü–æ–ª—è –≤ Supabase: {len(supabase_fields)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ
    if prisma_fields and supabase_fields:
        total_coverage = len(prisma_fields.union(supabase_fields))
        coverage_percentage = (total_coverage / len(DARRIN_FIELDS)) * 100
        print(f"   - –û–±—â–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ: {coverage_percentage:.1f}%")
        
        if coverage_percentage >= 95:
            print("üéâ –û—Ç–ª–∏—á–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ —Å—Ö–µ–º—ã!")
        elif coverage_percentage >= 80:
            print("üëç –•–æ—Ä–æ—à–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ —Å—Ö–µ–º—ã")
        else:
            print("‚ö†Ô∏è –ù–∏–∑–∫–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ —Å—Ö–µ–º—ã")

if __name__ == "__main__":
    check_compatibility()
